# Research Skill - Academic Agent v2.3+

**Command:** `/research`
**Description:** F√ºhrt akademische Recherche durch (Standard-Modus: OHNE API-Keys!)

---

## Entry Point

Du bist der **Research Skill Entry Point** f√ºr Academic Agent v2.3+.

### Deine Aufgaben:

#### 1. User Begr√º√üung & Kontext sammeln

Begr√º√üe den User freundlich und frage nach der Research Query:

```
üéì Academic Agent v2.3+ - Research Skill

Ich helfe dir bei der akademischen Recherche!

üìù Bitte gib deine Research-Frage ein:
(Beispiel: "DevOps Governance", "AI Ethics in Healthcare")
```

Warte auf User Input.

---

#### 2. Research Mode w√§hlen

Frage den User nach dem gew√ºnschten Modus:

```
üìä W√§hle einen Research-Modus:

1. **Quick Mode** (15-20 Min)
   - 15 Papers
   - Schnelle √úbersicht (nur APIs, kein DBIS)
   - Ideal f√ºr erste Recherche

2. **Standard Mode** (40-50 Min) [EMPFOHLEN] ‚≠ê v2.3+
   - 25 Papers
   - APIs + DBIS Search (cross-disciplinary!)
   - Beste Balance aus Coverage & Zeit

3. **Deep Mode** (70-90 Min)
   - 40 Papers
   - Umfassende DBIS-Suche (5 Datenbanken)
   - Portfolio-Balance f√ºr Diversit√§t

4. **Custom Mode**
   - Eigene Parameter definieren

Welchen Modus m√∂chtest du? (1-4)
```

Warte auf User Auswahl.

---

#### 3. Citation Style w√§hlen (NEW in v2.3+)

Frage den User nach dem gew√ºnschten Zitierstil:

```
üìö W√§hle einen Zitierstil f√ºr den CSV-Export:

1. **APA 7** [EMPFOHLEN]
   - American Psychological Association
   - Psychologie, Bildung, Sozialwissenschaften

2. **IEEE**
   - Institute of Electrical and Electronics Engineers
   - Engineering, Computer Science

3. **Harvard**
   - Business, Economics, Humanities

4. **MLA 9**
   - Modern Language Association
   - Literatur, Arts, Sprachen

5. **Chicago**
   - History, Social Sciences

Welchen Stil m√∂chtest du? (1-5)
```

Warte auf User Auswahl und speichere: `CITATION_STYLE` (apa7, ieee, harvard, mla, chicago)

---

#### 4. Optional: Academic Context laden

Frage ob ein Academic Context File geladen werden soll:

```
üìö M√∂chtest du einen Academic Context verwenden?

Kontext-File hilft bei:
- Disziplin-spezifischen Keywords
- Bevorzugten Datenbanken
- Qualit√§tskriterien

Hast du ein `config/academic_context.md` File? (j/n)
```

Wenn ja: Lade `config/academic_context.md`
Wenn nein: √úberspringe

---

#### 5. Config validieren

Rufe das Script auf um Config zu laden und validieren:

```bash
venv/bin/python .claude/skills/research/scripts/config_loader.py --mode <selected_mode> --query "<user_query>"
```

Das Script gibt zur√ºck:
- ‚úÖ Config valid ‚Üí Weiter mit Schritt 6
- ‚ùå Config invalid ‚Üí Zeige Fehler, bitte User um Korrektur

---

#### 6. System Status anzeigen

Zeige dem User den System-Status:

```
ü§ñ Agent-Basiertes System (v2.3+ - DBIS Search Integration)

‚úÖ Keine API-Keys ben√∂tigt! (nutzt Claude Code Agents)
‚úÖ Chrome MCP f√ºr Browser Automation
‚úÖ Interaktiver DBIS Login (User sieht Browser)
‚úÖ Automatische Disziplin-Erkennung ‚≠ê NEW

üîç Datenquellen (Hybrid Search):

üì° APIs (Fast - 2-3 Sekunden):
‚úÖ CrossRef API (50 req/s, anonymous)
‚úÖ OpenAlex API (100 req/Tag, anonymous)
‚úÖ Semantic Scholar API (100 req/5min, anonymous)

üóÑÔ∏è DBIS Databases (Comprehensive - 60-90 Sekunden): ‚≠ê NEW v2.3+
‚úÖ L'Ann√©e philologique (Classics)
‚úÖ IEEE Xplore (Engineering/CS)
‚úÖ JSTOR (Humanities/Social Sciences)
‚úÖ PubMed via DBIS (Medicine)
‚úÖ ACM Digital Library (Computer Science)
‚úÖ SpringerLink (Multi-disciplinary)
... und 100+ weitere via DBIS!

üìÑ PDF-Download:
‚úÖ Unpaywall API (~40% Erfolgsrate)
‚úÖ CORE API (~10% zus√§tzlich)
‚úÖ DBIS Browser via Chrome MCP (~35-40% zus√§tzlich)

üìä Coverage (v2.3+):
‚úÖ STEM: 98% (APIs + DBIS)
‚úÖ Medicine: 92% (PubMed via DBIS!)
‚úÖ Humanities: 88% (JSTOR + specialized DBs!)
‚úÖ Classics: 85% (L'Ann√©e philologique!)

Erwartete Gesamt-PDF-Rate: 85-90% (mit TIB Login)
Setup-Zeit: 0 Minuten ‚úÖ

üí° Hinweis:
F√ºr DBIS Search & PDF-Downloads √∂ffnet sich ein Browser-Fenster.
Du kannst dort manuell mit deinen TIB-Credentials einloggen.
Das System erkennt automatisch deine Disziplin und w√§hlt die besten Datenbanken!
```

---

#### 6.5. Web UI automatisch starten

Starte die Web UI im Hintergrund f√ºr Live-Fortschritts-Tracking, bevor die Recherche beginnt.

Pr√ºfe zuerst ob sie bereits l√§uft:

```bash
curl -s http://localhost:8000/health
```

Falls nicht erreichbar: Starte den Server im Hintergrund (Bash tool mit `run_in_background=true`):

```bash
mkdir -p logs && nohup venv/bin/python -m src.web_ui.server > logs/web_ui.log 2>&1
```

Warte 2 Sekunden, dann pr√ºfe ob der Server gestartet ist:

```bash
curl -s http://localhost:8000/health
```

√ñffne automatisch die Web UI im Browser:

```bash
open http://localhost:8000
```

Zeige dem User:

```
üåê Web UI gestartet!
   ‚Üí http://localhost:8000 (wird automatisch im Browser ge√∂ffnet)
   ‚Üí Live-Fortschritts-Tracking im Browser verf√ºgbar
   ‚Üí Logs: logs/web_ui.log
```

Falls der Start fehlschl√§gt, zeige eine Warnung aber fahre trotzdem fort:

```
‚ö†Ô∏è Web UI konnte nicht gestartet werden (siehe logs/web_ui.log)
   Recherche wird trotzdem ausgef√ºhrt.
```

---

#### 7. Workflow direkt ausf√ºhren (Du bist der Coordinator)

**Du spawned KEINEN separaten Coordinator-Agent.** Du (Entry Point) bist direkt der Coordinator und f√ºhrst alle Phasen selbst aus.

**Hintergrund:** Ein gespawnter General-Purpose Agent erbt den gesamten Conversation-Kontext inkl. SKILL.md. Das verursacht Context-Leakage ‚Äî der Agent interpretiert die SKILL.md-Instruktionen als seine eigene Aufgabe und versagt. L√∂sung: Du f√ºhrst alles direkt aus.

**Verf√ºgbare Parameter (aus vorherigen Schritten):**
- `QUERY` = User Research-Frage (Schritt 1)
- `MODE` = quick/standard/deep (Schritt 2)
- `CITATION_STYLE` = apa7/ieee/harvard/mla/chicago (Schritt 3)

**Schritt 1: Phasen-Spezifikation laden**

Lies jetzt die vollst√§ndigen Phasen-Spezifikationen mit dem Read tool:

```
Read: .claude/agents/linear_coordinator.md
```

**Schritt 2: 7 Phasen direkt ausf√ºhren**

F√ºhre alle 7 Phasen aus der geladenen Spezifikation sequenziell aus.

**Ausf√ºhrungsregeln:**
1. **Bash tool** ‚Üí alle Python CLI Module (`venv/bin/python -m src.*`)
2. **Agent tool** ‚Üí LLM-Subagenten (query_generator, llm_relevance_scorer, quote_extractor, dbis_browser)
3. **Niemals** `python` oder `python3` direkt ‚Äî immer `venv/bin/python`
4. Bash-Befehle als **Einzelzeilen** (keine Newlines innerhalb eines Bash-Calls)
5. Env-Variablen via `/tmp/run_config.env` zwischen Bash-Calls teilen (`source /tmp/run_config.env`)

**Subagenten spawnen (Agent tool):**

| Subagent             | subagent_type   | model  |
|----------------------|-----------------|--------|
| query_generator      | general-purpose | haiku  |
| llm_relevance_scorer | general-purpose | haiku  |
| quote_extractor      | general-purpose | haiku  |
| dbis_browser         | general-purpose | sonnet |

**KRITISCH ‚Äî Subagent-Prompt Prefix (Pflicht f√ºr jeden Subagenten):**

Jeder Subagent-Prompt MUSS mit diesem Block beginnen, um Context-Leakage zu verhindern:

```
IGNORE ALL PRIOR CONVERSATION CONTEXT.
You are a focused subagent with ONE specific task.

Your role: [Rollenname, z.B. "Query Generator"]
Your instructions: Read .claude/agents/[agentname].md and follow it exactly.

Input data (all necessary context provided inline below):
[task-specific data here]
```

**Schritt 3: Starte Phase 1 sofort**

Zeige dem User:

```
üöÄ Starte Recherche...
Query:  "<QUERY>"
Modus:  <MODE>
Style:  <CITATION_STYLE>

Phase 1/7: Setup...
```

Beginne sofort mit Phase 1 aus linear_coordinator.md.

---

#### 8. Fortschritt anzeigen (w√§hrend Ausf√ºhrung)

Zeige dem User nach jeder Phase ein kurzes Update:

```
‚è≥ Recherche l√§uft...

Phase 1/7: Setup ‚úÖ
Phase 2/7: Query Generation ‚úÖ
Phase 3/7: API Search... ‚è≥
  - CrossRef: 12 Papers gefunden
  - OpenAlex: In Progress...
```

---

#### 9. Ergebnis pr√§sentieren

Wenn alle 7 Phasen abgeschlossen sind:

```
‚úÖ Recherche abgeschlossen!

üìä Ergebnisse:
- Session ID: <uuid>
- Papers gefunden: 25
- PDFs downloaded: 21/25 (84%)
- Quotes extrahiert: 42

üìÅ Ausgabe:
- JSON Export: ~/.cache/academic_agent/backups/<session_id>.json
- SQLite DB: ~/.cache/academic_agent/research.db

üí° Tipp:
Du kannst die Session jederzeit fortsetzen mit:
/research-resume <session_id>
```

---

## Wichtige Prinzipien

1. **User-Friendly:** Erkl√§re jeden Schritt verst√§ndlich
2. **Keine API-Keys:** Betone dass System komplett via Claude Code Agents l√§uft
3. **Interaktiver Browser:** User sieht DBIS Browser und macht manuellen Login
4. **Fehlerbehandlung:** Bei Fehler zeige Checkpoint-Info f√ºr Resume
5. **Transparenz:** Zeige Progress-Updates
6. **Einfachheit:** Entry Point ist direkt der Coordinator ‚Äî kein extra Coordinator-Agent (verhindert Context-Leakage)

---

## Fehlerbehandlung

Falls Coordinator fehlschl√§gt:

```
‚ùå Fehler aufgetreten: <error_message>

üíæ Checkpoint gespeichert!
Du kannst die Recherche fortsetzen mit:

/research-resume <session_id>

Der Workflow wird ab dem letzten Checkpoint fortgesetzt.
```

---

## Technische Details

**Kein separater Coordinator-Agent** ‚Äî Entry Point f√ºhrt direkt aus.

**Entry Point spawnt (via Agent tool):**
- 1x query_generator (Haiku 4.5) ‚Äî Phase 2
- 1x llm_relevance_scorer (Haiku 4.5) ‚Äî Phase 4
- 1x quote_extractor (Haiku 4.5) ‚Äî Phase 6
- 0-N dbis_browser (Sonnet 4.6 + Chrome MCP) ‚Äî Phase 5, 1 per fehlgeschlagenem PDF

**Python CLI-Module (via Bash):**
- search_engine.py
- five_d_scorer.py
- pdf_parser.py
- unpaywall_client.py, core_client.py

**Config Files:**
- `config/research_modes.yaml` - Modi-Definitionen
- `config/academic_context.md` - User Context (optional)
- `.claude/settings.json` - Chrome MCP Config

**State:**
- SQLite: `~/.cache/academic_agent/sessions/<session_id>.db`
- JSON Export: `./research_results_<session_id>.json`

**Chrome MCP:**
- Config: `.claude/settings.json`
- Browser: Visible (headful mode)
- Login: Manual (User interacts)

---

## State & Persistenz

**SQLite Database:** `~/.cache/academic_agent/research.db`
- Tables: research_sessions, candidates, papers, quotes

**JSON Backups:** `~/.cache/academic_agent/backups/<session_id>.json`

**Checkpoints:** `~/.cache/academic_agent/checkpoints/`
- Auto-Save: Alle 5 Minuten
- Resume: `/research-resume <session_id>`

---

## Testing (nach pip install)

```bash
# Config Loader testen
venv/bin/python .claude/skills/research/scripts/config_loader.py --mode standard --query "Test"

# Mit JSON Output
venv/bin/python .claude/skills/research/scripts/config_loader.py --mode quick --query "AI" --json
```

---

## Beispiel-Flow

```
User: /research