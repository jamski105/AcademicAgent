"""
Markdown Exporter f√ºr Academic Agent v2.3+

Erstellt human-readable Markdown Summary Report.

Usage:
    from src.export.markdown_exporter import export_markdown

    export_markdown(results, output_path=Path("summary.md"))
"""

import json
from pathlib import Path
from typing import Dict, Any
from datetime import datetime


def export_markdown(results: Dict[str, Any], output_path: Path) -> None:
    """
    Export results as Markdown summary report

    Args:
        results: Results dict with query, mode, papers, quotes, etc.
        output_path: Output markdown file path
    """
    with open(output_path, 'w', encoding='utf-8') as f:
        # Header
        f.write(f"# Research Summary\n\n")
        f.write(f"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write(f"---\n\n")

        # Query & Mode
        f.write(f"## Query\n\n")
        f.write(f"**Research Question:** {results.get('query', 'N/A')}\n\n")
        f.write(f"**Mode:** {results.get('mode', 'standard')}\n\n")

        # Statistics
        f.write(f"## Statistics\n\n")
        stats = results.get('statistics', {})
        f.write(f"- **Papers Found:** {stats.get('papers_found', 0)}\n")
        f.write(f"- **Papers Ranked:** {stats.get('papers_ranked', 0)}\n")
        f.write(f"- **PDFs Downloaded:** {stats.get('pdfs_downloaded', 0)}/{stats.get('papers_ranked', 0)}")
        if stats.get('papers_ranked', 0) > 0:
            success_rate = (stats.get('pdfs_downloaded', 0) / stats.get('papers_ranked', 1)) * 100
            f.write(f" ({success_rate:.0f}%)")
        f.write(f"\n")
        f.write(f"- **Quotes Extracted:** {stats.get('quotes_extracted', 0)}\n\n")

        # Source Breakdown (v2.2)
        if 'sources' in stats or 'papers_from_api' in stats:
            f.write(f"## Source Breakdown\n\n")
            if 'papers_from_api' in stats:
                f.write(f"- **API Papers:** {stats.get('papers_from_api', 0)}\n")
            if 'papers_from_dbis' in stats:
                f.write(f"- **DBIS Papers:** {stats.get('papers_from_dbis', 0)}\n")
            if 'sources' in stats:
                f.write(f"\n**Detailed Sources:**\n\n")
                for source, count in stats['sources'].items():
                    f.write(f"- {source}: {count} papers\n")
            f.write(f"\n")

        # Top Papers
        papers = results.get('papers', [])[:5]
        if papers:
            f.write(f"## Top 5 Papers\n\n")
            for i, paper in enumerate(papers, 1):
                f.write(f"### {i}. {paper.get('title', 'Untitled')}\n\n")
                f.write(f"**Authors:** {', '.join(paper.get('authors', []))}\n\n")
                f.write(f"**Year:** {paper.get('year', 'N/A')}  \n")
                f.write(f"**Venue:** {paper.get('venue', 'N/A')}  \n")
                f.write(f"**DOI:** {paper.get('doi', 'N/A')}  \n")
                if 'score' in paper or 'scores' in paper:
                    score = paper.get('score') or paper.get('scores', {}).get('total', 0)
                    f.write(f"**Score:** {score:.3f}  \n")
                f.write(f"\n")

        # Sample Quotes
        quotes = results.get('quotes', [])[:5]
        if quotes:
            f.write(f"## Sample Quotes\n\n")
            for i, quote in enumerate(quotes, 1):
                f.write(f"**{i}.** \"{quote.get('text', '')}\"\n\n")
                f.write(f"   *‚Äî Page {quote.get('page', 'N/A')}*\n\n")

        # Footer
        f.write(f"---\n\n")
        f.write(f"*Generated by Academic Agent v2.3+*\n")

    print(f"‚úÖ Exported Markdown summary to {output_path}")


# CLI
def main():
    import argparse
    import sys

    parser = argparse.ArgumentParser(description="Markdown Exporter")
    parser.add_argument('--results', help='Input JSON results file')
    parser.add_argument('--output', help='Output markdown file')
    parser.add_argument('--test', action='store_true', help='Run test')

    args = parser.parse_args()

    if args.test:
        test_results = {
            "query": "DevOps Governance",
            "mode": "standard",
            "statistics": {
                "papers_found": 47,
                "papers_ranked": 25,
                "pdfs_downloaded": 22,
                "quotes_extracted": 45
            },
            "papers": [
                {
                    "title": "DevOps Governance Framework",
                    "authors": ["Smith, John", "Doe, Alice"],
                    "year": 2024,
                    "venue": "IEEE Software",
                    "doi": "10.1109/ICSE.2023.00042",
                    "score": 0.95
                }
            ],
            "quotes": [
                {"text": "DevOps governance requires continuous compliance.", "page": 5}
            ]
        }

        output_path = Path("test_summary.md")
        export_markdown(test_results, output_path)

        print(f"\nüìÑ Markdown Preview:")
        print(output_path.read_text())

        output_path.unlink()
        print("\n‚úÖ Markdown Exporter test passed!")
        sys.exit(0)

    if not args.results or not args.output:
        parser.error("--results and --output required (unless --test)")

    try:
        with open(args.results, 'r') as f:
            results = json.load(f)

        export_markdown(results, Path(args.output))

    except Exception as e:
        print(f"‚ùå Error: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()
