# ğŸ“ AcademicAgent

**Version:** 3.0
**Autonomes akademisches Literatur-Recherche-System**

AcademicAgent ist ein Claude-basierter Forschungsassistent, der den gesamten Literaturrecherche-Prozess automatisiert - von der Datenbanksuche bis zur Zitat-Extraktion. Er liefert 18 hochwertige VerÃ¶ffentlichungen mit zitierfÃ¤higen Zitaten in 3,5-4 Stunden.

---

## ğŸŒŸ Hauptfunktionen

- **VollstÃ¤ndig autonom**: 7-Phasen-Workflow mit minimaler menschlicher Aufsicht
- **Intelligente Datenbankauswahl**: 30 kuratierte Top-Datenbanken + dynamische DBIS-Erkennung
- **5D-Bewertungssystem**: Zitationen, AktualitÃ¤t, Relevanz, JournalqualitÃ¤t, Open Access
- **Iterative Suche**: Durchsucht jeweils 5 Datenbanken bis Ziel erreicht (40% weniger Datenbanken, 42% schneller)
- **PDF-Extraktion**: Natives `pdftotext` - 5x schneller als browserbasierte Extraktion
- **Zitatbibliothek**: Strukturiertes JSON mit Seitenzahlen und Relevanzscores
- **Fehlerwiederherstellung**: Automatisches State-Management mit FortsetzungsfÃ¤higkeit
- **Sicherheit**: Schutz gegen Prompt-Injection-Angriffe (9/10 Score)

---

## ğŸš€ Schnellstart

### Voraussetzungen

- macOS oder Linux
- Chrome-Browser
- UniversitÃ¤ts-VPN-Zugang (fÃ¼r lizenzierte Datenbanken)

### Installation

```bash
# Repository klonen
git clone https://github.com/yourusername/AcademicAgent.git
cd AcademicAgent

# Setup ausfÃ¼hren (installiert alle AbhÃ¤ngigkeiten)
bash setup.sh

# Chrome mit Remote-Debugging starten
bash scripts/start_chrome_debug.sh
```

### Deine erste Recherche

```bash
# VS Code Ã¶ffnen
code .

# Claude Code Chat starten
# Cmd+Shift+P â†’ "Claude Code: Start Chat"

# Im Chat:
/academicagent
```

Das war's! Der Agent wird:
1. Dich durch die Erstellung einer Recherche-Konfiguration fÃ¼hren
2. Datenbanken Ã¼ber DBIS durchsuchen
3. Kandidaten mit 5D-Bewertung ranken
4. Die Top 18 PDFs herunterladen
5. Relevante Zitate extrahieren
6. Bibliographie generieren

**GeschÃ¤tzte Zeit:** 3,5-4 Stunden (grÃ¶ÃŸtenteils automatisiert)

---

## ğŸ“‹ Skills-Ãœbersicht

### Haupt-Skill

| Skill | Beschreibung | Wann verwenden |
|-------|-------------|----------------|
| **`/academicagent`** | Haupt-Orchestrator - fÃ¼hrt alle 7 Phasen aus | Immer fÃ¼r neue Recherchen |

### Debug-Skills (Optional)

| Skill | Beschreibung | Wann verwenden |
|-------|-------------|----------------|
| `/setup-agent` | Interaktive Konfig-Generierung | Konfigs erstellen ohne Recherche zu starten |
| `/browser-agent` | Browser-Automatisierungs-Tests | CDP/UI-Navigationsprobleme debuggen |
| `/search-agent` | Boolean-Suchstring-Tests | Query-Generierung debuggen |
| `/scoring-agent` | 5D-Ranking-Tests | Kandidaten-Ranking debuggen |
| `/extraction-agent` | PDF-Extraktions-Tests | Zitat-Extraktion debuggen |

---

## ğŸ¯ Der 7-Phasen-Workflow

Der Orchestrator verwaltet alle Phasen automatisch mit 5 menschlichen Checkpoints:

| Phase | Name | Dauer | Checkpoint | Beschreibung |
|-------|------|-------|------------|--------------|
| **0** | DBIS-Navigation | 15-20 Min | âœ… | Navigation zu Datenbanken Ã¼ber DBIS-Portal |
| **1** | Suchstring-Generierung | 5-10 Min | âœ… | Boolean-Queries aus Keywords generieren |
| **2** | Datenbanksuche | 90-120 Min | âŒ | Iterative Suche (jeweils 5 DBs) |
| **3** | 5D-Bewertung & Ranking | 20-30 Min | âœ… | Kandidaten ranken, Top 27 auswÃ¤hlen â†’ User wÃ¤hlt 18 |
| **4** | PDF-Download | 20-30 Min | âŒ | AusgewÃ¤hlte Papers herunterladen |
| **5** | Zitat-Extraktion | 30-45 Min | âœ… | Relevante Zitate mit Seitenzahlen extrahieren |
| **6** | Finalisierung | 15-20 Min | âœ… | Bibliographie und Ausgaben generieren |

### Checkpoints (Human-in-the-Loop)

- **Checkpoint 0:** Datenbankliste validieren
- **Checkpoint 1:** Suchstrings freigeben
- **Checkpoint 3:** Top 18 aus Top 27 Kandidaten auswÃ¤hlen
- **Checkpoint 5:** ZitatqualitÃ¤t prÃ¼fen
- **Checkpoint 6:** Finale Ausgaben bestÃ¤tigen

---

## ğŸ’¾ Ausgabe-Struktur

```
runs/
â””â”€â”€ 2026-02-18_14-30-00/
    â”œâ”€â”€ downloads/              # 18 PDF-Dateien
    â”œâ”€â”€ metadata/
    â”‚   â”œâ”€â”€ research_state.json # Fortsetzungs-State
    â”‚   â”œâ”€â”€ candidates.json     # Gerankte Kandidaten
    â”‚   â”œâ”€â”€ search_strings.json # Generierte Queries
    â”‚   â””â”€â”€ config.md           # Recherche-Konfiguration
    â”œâ”€â”€ outputs/
    â”‚   â”œâ”€â”€ quote_library.json  # Extrahierte Zitate
    â”‚   â”œâ”€â”€ bibliography.bib    # BibTeX-Zitationen
    â”‚   â””â”€â”€ summary.md          # Recherche-Zusammenfassung
    â””â”€â”€ logs/
        â”œâ”€â”€ phase_*.log         # Phasen-AusfÃ¼hrungslogs
        â””â”€â”€ cdp_health.log      # Browser-Monitoring-Logs
```

---

## ğŸ—ƒï¸ Datenbank-Strategie V3.0

### Kuratierte Top-Datenbanken

AcademicAgent verwendet eine kuratierte Liste von TOP-Datenbanken pro Disziplin:

**InterdisziplinÃ¤r (Top 10):**
- Web of Science, Scopus, Google Scholar, JSTOR
- SpringerLink, ScienceDirect, PubMed, arXiv
- BASE, CORE

**Informatik:**
- ACM Digital Library, IEEE Xplore, DBLP
- arXiv, Scopus

**Wirtschaft & BWL:**
- WISO, Statista, Business Source Elite
- EconBiz, RePEc, SSRN, Scopus

**Jura:**
- juris, beck-online, Wolters Kluwer Online
- Staudinger BGB, HeinOnline, Westlaw

### DBIS Dynamische Erkennung

ZusÃ¤tzlich zur kuratierten Liste erkennt der Agent dynamisch weitere Datenbanken Ã¼ber DBIS:

1. Durchsucht DBIS mit Recherche-Keywords + Disziplin
2. Bewertet Ergebnisse nach Beschreibungs-Relevanz (0-100)
3. FÃ¼gt Datenbanken mit Score â‰¥ 60 zur Suchliste hinzu
4. Integriert sich mit iterativer Suchstrategie

**Ergebnis:** 40% weniger durchsuchte Datenbanken, 42% schnellere AusfÃ¼hrung, hÃ¶here Relevanz

---

## ğŸ”„ Iterative Suchstrategie

Anstatt alle Datenbanken im Voraus zu durchsuchen, sucht der Agent iterativ:

```
Phase 2: Datenbanksuche (Iterativ)
â”œâ”€ Iteration 1: Top 5 Datenbanken â†’ 23 Kandidaten
â”œâ”€ Check: Ziel erreicht? (Ziel: 50) â†’ NEIN
â”œâ”€ Iteration 2: NÃ¤chste 5 Datenbanken â†’ 51 Kandidaten (gesamt)
â””â”€ Check: Ziel erreicht? â†’ JA â†’ Vorzeitig stoppen
```

**Vorteile:**
- Stoppt wenn genÃ¼gend Kandidaten gefunden wurden
- Spart Zeit bei weniger relevanten Datenbanken
- Priorisiert hochwertige Quellen

---

## ğŸ§  5D-Bewertungssystem

Jeder Kandidat wird Ã¼ber 5 Dimensionen bewertet:

| Dimension | Gewichtung | Beschreibung |
|-----------|------------|--------------|
| **Zitationen** | 20% | Google Scholar Zitationsanzahl (normalisiert) |
| **AktualitÃ¤t** | 20% | Publikationsjahr (2024 = 100, verfÃ¤llt 5 Pkte/Jahr) |
| **Relevanz** | 25% | Keyword-Match in Titel/Abstract |
| **JournalqualitÃ¤t** | 20% | Impact Factor / Konferenz-Rang |
| **Open Access** | 15% | PDF Ã¶ffentlich verfÃ¼gbar |

**Finaler Score:** 0-100 Punkte

**Beispiel:**
```json
{
  "title": "Lean Governance in DevOps Teams",
  "score": 87,
  "breakdown": {
    "citations": 18,    // 350 Zitationen â†’ 18 Pkt
    "recency": 19,      // 2023 â†’ 19 Pkt
    "relevance": 23,    // Starker Keyword-Match â†’ 23 Pkt
    "quality": 18,      // Top-Konferenz â†’ 18 Pkt
    "open_access": 9    // PDF verfÃ¼gbar â†’ 9 Pkt
  }
}
```

---

## ğŸ› ï¸ Konfiguration

### Eine Recherche-Konfiguration erstellen

Konfigurationen werden in [config/](config/) als Markdown-Dateien gespeichert. Erstelle eine Ã¼ber:

```bash
# Option 1: Interaktives Setup (empfohlen)
# In Claude Code Chat:
/academicagent
# Agent fÃ¼hrt dich durch die Konfig-Erstellung

# Option 2: Manuelles Setup
/setup-agent
# Erstellt Konfig ohne Recherche zu starten

# Option 3: Beispiel-Template verwenden
cp config/.example/academic_context_cs_example.md config/my_research.md
# Manuell bearbeiten
```

### Konfig-Struktur

```markdown
# Recherche-Konfiguration

## Forschungsfrage
Wie ermÃ¶glichen Lean-Prinzipien Governance in DevOps-Teams?

## Keywords
- PrimÃ¤r: Lean Governance, DevOps
- SekundÃ¤r: Continuous Delivery, Agile Teams
- Verwandt: IT Governance, Process Automation

## Ziel-Disziplinen
- Informatik
- Software Engineering
- Business Management

## Suchparameter
- Jahresbereich: 2015-2024
- Sprachen: Englisch, Deutsch
- Dokumenttypen: Journal-Artikel, Konferenz-Papers

## QualitÃ¤tsfilter
- Min. Zitationen: 10
- Open Access bevorzugt: Ja
- Zielanzahl: 18 Papers
```

Siehe [config/academic_context.md](config/academic_context.md) fÃ¼r vollstÃ¤ndiges Template.

---

## ğŸ”„ Fehlerwiederherstellung & Fortsetzung

### Nach Unterbrechung fortsetzen

Falls die Recherche unterbrochen wird (Absturz, Terminal geschlossen, etc.):

```bash
# 1. State validieren
python3 scripts/validate_state.py runs/[Timestamp]/metadata/research_state.json

# Ausgabe zeigt:
# âœ… State gÃ¼ltig
# Zuletzt abgeschlossen: Phase 2
# NÃ¤chste: Phase 3
# Checksum: OK

# 2. Chrome neu starten
bash scripts/start_chrome_debug.sh

# 3. In VS Code fortsetzen
code .
# In Claude Code Chat:
/academicagent

# Agent setzt automatisch bei Phase 3 fort
```

### HÃ¤ufige Probleme

Siehe [ERROR_RECOVERY.md](ERROR_RECOVERY.md) fÃ¼r detailliertes Troubleshooting:

- **CDP-Verbindungsfehler** - Chrome antwortet nicht
- **CAPTCHA-Erkennung** - Manuelle LÃ¶sung erforderlich
- **Login erforderlich** - UniversitÃ¤ts-Authentifizierung nÃ¶tig
- **Rate Limits** - Automatischer Retry mit Backoff
- **Netzwerkfehler** - VPN/Verbindungsprobleme
- **State-Korruption** - Wiederherstellungsverfahren

### CDP-Health-Monitor

Der Orchestrator Ã¼berwacht automatisch die Chrome-Gesundheit alle 5 Minuten:
- PrÃ¼ft CDP-Verbindung (Port 9222)
- Ãœberwacht Speichernutzung (warnt bei >2GB)
- Startet Chrome bei Absturz automatisch neu
- Loggt in `runs/[Timestamp]/logs/cdp_health.log`

---

## ğŸ›¡ï¸ Sicherheit

AcademicAgent ist gegen Prompt-Injection-Angriffe gehÃ¤rtet. Wichtige MaÃŸnahmen:

- **Instruktions-Hierarchie**: Externe Inhalte werden nur als DATEN behandelt
- **Input-Sanitierung**: HTML-Bereinigung, Injection-Pattern-Erkennung
- **Action Gate**: Validiert Tool-Aufrufe vor AusfÃ¼hrung
- **Domain-Whitelist**: Nur akademische Datenbanken erlaubt (Ã¼ber DBIS)
- **Least Privilege**: BeschrÃ¤nkter Dateisystem- und Netzwerkzugriff
- **Reader/Actor-Trennung**: Read-only-Agents kÃ¶nnen keine Befehle ausfÃ¼hren

**Sicherheits-Score:** 9/10 (90% der MaÃŸnahmen implementiert)

Siehe [SECURITY.md](SECURITY.md) fÃ¼r vollstÃ¤ndige Sicherheitsdokumentation und Red-Team-Tests.

---

## ğŸ“Š Typische Recherche-Session

```
User startet Recherche (00:00)
  â†“
/academicagent
  â†“
Interaktive Konfig-Erstellung (00:00 - 00:10)
  â†’ Forschungsfrage, Keywords, Filter
  â†“
[Checkpoint 0] Datenbanken validieren (00:15)
  â†’ Agent zeigt: 8 kuratierte + 3 DBIS entdeckte = 11 Datenbanken
  â†’ User genehmigt
  â†“
[Checkpoint 1] Suchstrings prÃ¼fen (00:25)
  â†’ Agent zeigt Boolean-Queries fÃ¼r jede Datenbank
  â†’ User genehmigt
  â†“
Phase 2 lÃ¤uft automatisch (00:25 - 02:30)
  â†’ Iteration 1: Top 5 Datenbanken â†’ 23 Kandidaten
  â†’ Iteration 2: NÃ¤chste 5 Datenbanken â†’ 52 Kandidaten â†’ STOPP
  â†“
[Checkpoint 3] Top 18 aus Top 27 auswÃ¤hlen (02:30)
  â†’ Agent rankt alle Kandidaten nach 5D-Score
  â†’ Zeigt Top 27 mit Scores
  â†’ User wÃ¤hlt Top 18
  â†“
Phase 4 lÃ¤uft automatisch (02:30 - 03:00)
  â†’ LÃ¤dt 18 PDFs nach runs/[Timestamp]/downloads/
  â†“
Phase 5 lÃ¤uft automatisch (03:00 - 03:45)
  â†’ Extrahiert Zitate aus allen PDFs mit pdftotext
  â†’ 40-50 relevante Zitate mit Seitenzahlen
  â†“
[Checkpoint 5] ZitatqualitÃ¤t prÃ¼fen (03:45)
  â†’ Agent zeigt Beispielzitate
  â†’ User genehmigt
  â†“
Phase 6 lÃ¤uft automatisch (03:45 - 04:00)
  â†’ Generiert bibliography.bib (BibTeX)
  â†’ Generiert quote_library.json
  â†’ Generiert summary.md
  â†“
[Checkpoint 6] Ausgaben bestÃ¤tigen (04:00)
  â†’ Agent zeigt Ausgabe-Pfade
  â†’ User genehmigt
  â†“
âœ… Recherche abgeschlossen! (04:00)
```

**Gesamte aktive Zeit:** ~15-20 Minuten (Checkpoints + Konfig)
**Gesamte verstrichene Zeit:** ~4 Stunden (grÃ¶ÃŸtenteils automatisiert)

---

## ğŸ¨ Architektur

### Agent-Struktur

```
Orchestrator (/academicagent)
â”œâ”€â”€ Phase 0: DBIS-Navigation
â”‚   â”œâ”€â”€ Task: browser-agent
â”‚   â””â”€â”€ Entdeckt Datenbanken Ã¼ber DBIS
â”œâ”€â”€ Phase 1: Suchstring-Generierung
â”‚   â”œâ”€â”€ Task: search-agent
â”‚   â””â”€â”€ Erstellt Boolean-Queries
â”œâ”€â”€ Phase 2: Datenbanksuche (Iterativ)
â”‚   â”œâ”€â”€ Task: browser-agent (Schleife)
â”‚   â””â”€â”€ Durchsucht 5 DBs pro Iteration
â”œâ”€â”€ Phase 3: 5D-Bewertung & Ranking
â”‚   â”œâ”€â”€ Task: scoring-agent
â”‚   â””â”€â”€ Rankt alle Kandidaten
â”œâ”€â”€ Phase 4: PDF-Download
â”‚   â”œâ”€â”€ Task: browser-agent
â”‚   â””â”€â”€ LÃ¤dt ausgewÃ¤hlte Papers herunter
â”œâ”€â”€ Phase 5: Zitat-Extraktion
â”‚   â”œâ”€â”€ Task: extraction-agent
â”‚   â””â”€â”€ Extrahiert Zitate mit pdftotext
â””â”€â”€ Phase 6: Finalisierung
    â”œâ”€â”€ Python-Scripte
    â””â”€â”€ Generiert Ausgaben
```

### Tools & Technologien

- **Browser-Steuerung**: Chrome DevTools Protocol (CDP) via Playwright
- **PDF-Verarbeitung**: `pdftotext` (poppler-utils) + `grep`
- **State-Management**: JSON-Dateien mit SHA-256-Checksummen
- **Datenbank-Erkennung**: DBIS-Portal + WebFetch
- **Logging**: Strukturierte Logs pro Phase (JSON)
- **Sicherheit**: Domain-Validierung, Input-Sanitierung, Action-Gating

---

## ğŸ§ª Testing & Validierung

### Chrome-CDP-Verbindung testen

```bash
# Chrome starten
bash scripts/start_chrome_debug.sh

# 3 Sekunden warten
sleep 3

# Verbindung testen
curl http://localhost:9222/json/version
# Sollte Chrome-Versionsinformationen zurÃ¼ckgeben
```

### Sicherheitstests ausfÃ¼hren

```bash
# VollstÃ¤ndige Red-Team-Testsuite ausfÃ¼hren
bash tests/red_team/run_tests.sh

# Erwartet: 6/10 automatisierte Tests bestehen (60%)
# 4/10 erfordern manuelle Verifikation
```

### Recherche-State validieren

```bash
# State-Datei-IntegritÃ¤t prÃ¼fen
python3 scripts/validate_state.py runs/[Timestamp]/metadata/research_state.json

# Zeigt:
# - Aktuelle Phase
# - Zuletzt abgeschlossene Phase
# - NÃ¤chste ausstehende Phase
# - Checksum-Verifizierung
# - FortsetzungsfÃ¤higkeit
```

---

## ğŸ”§ Erweiterte Nutzung

### Von spezifischer Phase fortsetzen

```bash
# In Claude Code Chat:
/academicagent

# Bei Aufforderung Run-Verzeichnis angeben:
runs/2026-02-18_14-30-00

# Agent lÃ¤dt State und fragt:
# "State zeigt Phase 2 abgeschlossen. Von Phase 3 fortsetzen?"
# â†’ ja
```

### Benutzerdefinierte Datenbank hinzufÃ¼gen

Bearbeite [config/database_disciplines.yaml](config/database_disciplines.yaml):

```yaml
- name: Benutzerdefinierte Datenbank
  disciplines:
    - Deine Disziplin
  url: custom-db.com
  access: Subscription
  api_available: false
  base_score: 85
  priority: 2
  notes: "Beschreibung deiner benutzerdefinierten Datenbank"
```

### Iterative Suchparameter anpassen

Bearbeite Konfig um Suchverhalten zu Ã¤ndern:

```markdown
## Suchparameter
- Databases Per Iteration: 5    # Auf 3 oder 10 Ã¤ndern
- Target Candidates: 50          # Zielanzahl Ã¤ndern
- Max Iterations: 5              # Maximale Iterationen begrenzen
- Min Candidates Per DB: 3       # Unproduktive DBs Ã¼berspringen
```

### Zitatbibliothek nach Word exportieren

```bash
# JSON in formatiertes Word-Dokument konvertieren
# (BenÃ¶tigt pandoc - installiert via setup.sh)
python3 scripts/export_quotes.py \
  runs/[Timestamp]/outputs/quote_library.json \
  output.docx
```

---

## ğŸ“– ZusÃ¤tzliche Dokumentation

- **[ERROR_RECOVERY.md](ERROR_RECOVERY.md)** - Umfassender Fehlerbehandlungs-Guide
- **[SECURITY.md](SECURITY.md)** - SicherheitshÃ¤rtung & Red-Team-Tests
- **[docs/DBIS_USAGE.md](docs/DBIS_USAGE.md)** - Technische DBIS-Integration (fÃ¼r Agents)
- **[config/database_disciplines.yaml](config/database_disciplines.yaml)** - Datenbank-Katalog

---

## ğŸ¤ Beitragen

BeitrÃ¤ge sind willkommen! Verbesserungsbereiche:

1. **Datenbank-Abdeckung**
   - Disziplin-spezifische Datenbanken hinzufÃ¼gen
   - DBIS-Relevanz-Scoring verbessern

2. **Bewertungsalgorithmus**
   - H-Index fÃ¼r JournalqualitÃ¤t integrieren
   - Domain-spezifisches Relevanz-Scoring hinzufÃ¼gen

3. **Internationalisierung**
   - Mehrsprachige Suchstrings
   - UnterstÃ¼tzung nicht-englischer Datenbanken

4. **Ausgabeformate**
   - Zitierstile (APA, MLA, Chicago)
   - Export zu Zotero, Mendeley, EndNote

5. **BenutzeroberflÃ¤che**
   - Webbasierte Konfigurations-UI
   - Echtzeit-Fortschritts-Dashboard

---

## ğŸ› Bekannte EinschrÃ¤nkungen

1. **DBIS-AbhÃ¤ngigkeit**: BenÃ¶tigt universitÃ¤ren DBIS-Zugang
2. **Manueller Login**: Einige Datenbanken benÃ¶tigen menschliche Authentifizierung
3. **CAPTCHA-Handling**: Erfordert manuelle LÃ¶sung
4. **Rate Limits**: Aggressive Suche kann Rate Limits auslÃ¶sen
5. **PDF-Extraktion**: QualitÃ¤t hÃ¤ngt von PDF-Textebene ab

---

## ğŸ“„ Lizenz

MIT License - Siehe LICENSE-Datei fÃ¼r Details

---

## ğŸ™ Danksagungen

- **Anthropic** - Claude Code und Agent SDK
- **DBIS** - Database Information System (UniversitÃ¤t Regensburg)
- **Poppler** - PDF-Textextraktions-Bibliothek
- **Playwright** - Chrome DevTools Protocol Client

---

## ğŸ“ Support & Kontakt

- **Issues**: [GitHub Issues](https://github.com/yourusername/AcademicAgent/issues)
- **Diskussionen**: [GitHub Discussions](https://github.com/yourusername/AcademicAgent/discussions)
- **E-Mail**: your-email@example.com
- **Dokumentation**: Siehe Docs in diesem Repository

---

## ğŸ”„ Versionshistorie

- **v3.0** (2026-02-18) - Datenbank-Strategie V3.0 mit dynamischer DBIS-Erkennung
- **v2.5** (Vorherig) - Iterative Datenbanksuche
- **v2.0** (Vorherig) - 5D-Bewertungssystem
- **v1.0** (Vorherig) - Erstes Release

---

**Viel Erfolg bei der Recherche! ğŸ“šğŸ¤–**
