# üéì AcademicAgent

**Version:** 3.3 (Validation-Gate & MANDATORY Encryption Edition)
**Autonomes akademisches Literatur-Recherche-System**

> ‚ö†Ô∏è **WICHTIG: macOS ONLY**
>
> Dieses System ist **ausschlie√ülich f√ºr macOS** entwickelt und getestet.
> - Erfordert macOS-spezifische Pfade (`/Applications/Google Chrome.app`)
> - Nutzt macOS-spezifische Befehle (`stat -f`, `lsof`, `open`)
> - Homebrew als Paketmanager
>
> **Linux/Windows werden NICHT unterst√ºtzt.**

AcademicAgent ist ein Claude-basierter Forschungsassistent, der den gesamten Literaturrecherche-Prozess automatisiert - von der Datenbanksuche bis zur Zitat-Extraktion. Er liefert 18 hochwertige Ver√∂ffentlichungen mit zitierf√§higen Zitaten in 3,5-4 Stunden.

---

## üåü Hauptfunktionen

- **Vollst√§ndig autonom**: 7-Phasen-Workflow mit minimaler menschlicher Aufsicht
- **Intelligente Datenbankauswahl**: 30 kuratierte Top-Datenbanken + dynamische DBIS-Erkennung
- **5D-Bewertungssystem**: Zitationen, Aktualit√§t, Relevanz, Journalqualit√§t, Open Access
- **Iterative Suche**: Durchsucht jeweils 5 Datenbanken bis Ziel erreicht (40% weniger Datenbanken, 42% schneller)
- **PDF-Extraktion**: Natives `pdftotext` - 5x schneller als browserbasierte Extraktion
- **Zitatbibliothek**: Strukturiertes JSON mit Seitenzahlen und Relevanzscores
- **Fehlerwiederherstellung**: Automatisches State-Management mit Fortsetzungsf√§higkeit
- **Sicherheit**: Defense-in-Depth mit Validation-Gate, Encryption-at-Rest, Retry-Enforcement (9.8/10 Score)

---

## üöÄ Schnellstart

### Voraussetzungen

- **macOS** (10.15 Catalina oder neuer empfohlen)
- Google Chrome Browser
- Universit√§ts-VPN-Zugang (f√ºr lizenzierte Datenbanken)
- Homebrew Paketmanager (wird automatisch installiert falls nicht vorhanden)

### Installation

```bash
# Repository klonen
git clone https://github.com/jamski105/AcademicAgent.git
cd AcademicAgent

# Setup ausf√ºhren (installiert alle Abh√§ngigkeiten)
bash setup.sh

# Chrome mit Remote-Debugging starten
bash scripts/start_chrome_debug.sh
```

### Deine erste Recherche

```bash
# VS Code √∂ffnen
code .

# Claude Code Chat starten
# Cmd+Shift+P ‚Üí "Claude Code: Start Chat"

# Im Chat:
/academicagent
```

Das war's! Der Agent wird:
1. Dich durch die Erstellung einer Recherche-Konfiguration f√ºhren
2. Datenbanken √ºber DBIS durchsuchen
3. Kandidaten mit 5D-Bewertung ranken
4. Die Top 18 PDFs herunterladen
5. Relevante Zitate extrahieren
6. Bibliographie generieren

**Gesch√§tzte Zeit:** 3,5-4 Stunden (gr√∂√ütenteils automatisiert)

---

## üìã Skills-√úbersicht

### Haupt-Skill

| Skill | Beschreibung | Wann verwenden |
|-------|-------------|----------------|
| **`/academicagent`** | Haupt-Orchestrator - f√ºhrt alle 7 Phasen aus | Immer f√ºr neue Recherchen |

### Debug-Skills (Optional)

| Skill | Beschreibung | Wann verwenden |
|-------|-------------|----------------|
| `/setup-agent` | Interaktive Konfig-Generierung | Konfigs erstellen ohne Recherche zu starten |
| `/browser-agent` | Browser-Automatisierungs-Tests | CDP/UI-Navigationsprobleme debuggen |
| `/search-agent` | Boolean-Suchstring-Tests | Query-Generierung debuggen |
| `/scoring-agent` | 5D-Ranking-Tests | Kandidaten-Ranking debuggen |
| `/extraction-agent` | PDF-Extraktions-Tests | Zitat-Extraktion debuggen |

---

## üéØ Der 7-Phasen-Workflow

Der Orchestrator verwaltet alle Phasen automatisch mit 5 menschlichen Checkpoints:

| Phase | Name | Dauer | Checkpoint | Beschreibung |
|-------|------|-------|------------|--------------|
| **0** | DBIS-Navigation | 15-20 Min | ‚úÖ | Navigation zu Datenbanken √ºber DBIS-Portal |
| **1** | Suchstring-Generierung | 5-10 Min | ‚úÖ | Boolean-Queries aus Keywords generieren |
| **2** | Datenbanksuche | 90-120 Min | ‚ùå | Iterative Suche (jeweils 5 DBs) |
| **3** | 5D-Bewertung & Ranking | 20-30 Min | ‚úÖ | Kandidaten ranken, Top 27 ausw√§hlen ‚Üí User w√§hlt 18 |
| **4** | PDF-Download | 20-30 Min | ‚ùå | Ausgew√§hlte Papers herunterladen |
| **5** | Zitat-Extraktion | 30-45 Min | ‚úÖ | Relevante Zitate mit Seitenzahlen extrahieren |
| **6** | Finalisierung | 15-20 Min | ‚úÖ | Bibliographie und Ausgaben generieren |

### Checkpoints (Human-in-the-Loop)

- **Checkpoint 0:** Datenbankliste validieren
- **Checkpoint 1:** Suchstrings freigeben
- **Checkpoint 3:** Top 18 aus Top 27 Kandidaten ausw√§hlen
- **Checkpoint 5:** Zitatqualit√§t pr√ºfen
- **Checkpoint 6:** Finale Ausgaben best√§tigen

---

## üíæ Ausgabe-Struktur

```
runs/
‚îî‚îÄ‚îÄ 2026-02-18_14-30-00/
    ‚îú‚îÄ‚îÄ downloads/              # 18 PDF-Dateien
    ‚îú‚îÄ‚îÄ metadata/
    ‚îÇ   ‚îú‚îÄ‚îÄ research_state.json # Fortsetzungs-State
    ‚îÇ   ‚îú‚îÄ‚îÄ candidates.json     # Gerankte Kandidaten
    ‚îÇ   ‚îú‚îÄ‚îÄ search_strings.json # Generierte Queries
    ‚îÇ   ‚îî‚îÄ‚îÄ config.md           # Recherche-Konfiguration
    ‚îú‚îÄ‚îÄ outputs/
    ‚îÇ   ‚îú‚îÄ‚îÄ quote_library.json  # Extrahierte Zitate
    ‚îÇ   ‚îú‚îÄ‚îÄ bibliography.bib    # BibTeX-Zitationen
    ‚îÇ   ‚îî‚îÄ‚îÄ summary.md          # Recherche-Zusammenfassung
    ‚îî‚îÄ‚îÄ logs/
        ‚îú‚îÄ‚îÄ phase_*.log         # Phasen-Ausf√ºhrungslogs
        ‚îî‚îÄ‚îÄ cdp_health.log      # Browser-Monitoring-Logs
```

---

## üóÉÔ∏è Datenbank-Strategie V3.0

### Kuratierte Top-Datenbanken

AcademicAgent verwendet eine kuratierte Liste von TOP-Datenbanken pro Disziplin:

**Interdisziplin√§r (Top 10):**
- Web of Science, Scopus, Google Scholar, JSTOR
- SpringerLink, ScienceDirect, PubMed, arXiv
- BASE, CORE

**Informatik:**
- ACM Digital Library, IEEE Xplore, DBLP
- arXiv, Scopus

**Wirtschaft & BWL:**
- WISO, Statista, Business Source Elite
- EconBiz, RePEc, SSRN, Scopus

**Jura:**
- juris, beck-online, Wolters Kluwer Online
- Staudinger BGB, HeinOnline, Westlaw

### DBIS Dynamische Erkennung

Zus√§tzlich zur kuratierten Liste erkennt der Agent dynamisch weitere Datenbanken √ºber DBIS:

1. Durchsucht DBIS mit Recherche-Keywords + Disziplin
2. Bewertet Ergebnisse nach Beschreibungs-Relevanz (0-100)
3. F√ºgt Datenbanken mit Score ‚â• 60 zur Suchliste hinzu
4. Integriert sich mit iterativer Suchstrategie

**Ergebnis:** 40% weniger durchsuchte Datenbanken, 42% schnellere Ausf√ºhrung, h√∂here Relevanz

---

## üîÑ Iterative Suchstrategie

Anstatt alle Datenbanken im Voraus zu durchsuchen, sucht der Agent iterativ:

```
Phase 2: Datenbanksuche (Iterativ)
‚îú‚îÄ Iteration 1: Top 5 Datenbanken ‚Üí 23 Kandidaten
‚îú‚îÄ Check: Ziel erreicht? (Ziel: 50) ‚Üí NEIN
‚îú‚îÄ Iteration 2: N√§chste 5 Datenbanken ‚Üí 51 Kandidaten (gesamt)
‚îî‚îÄ Check: Ziel erreicht? ‚Üí JA ‚Üí Vorzeitig stoppen
```

**Vorteile:**
- Stoppt wenn gen√ºgend Kandidaten gefunden wurden
- Spart Zeit bei weniger relevanten Datenbanken
- Priorisiert hochwertige Quellen

---

## üß† 5D-Bewertungssystem

Jeder Kandidat wird √ºber 5 Dimensionen bewertet:

| Dimension | Gewichtung | Beschreibung |
|-----------|------------|--------------|
| **Zitationen** | 20% | Google Scholar Zitationsanzahl (normalisiert) |
| **Aktualit√§t** | 20% | Publikationsjahr (2024 = 100, verf√§llt 5 Pkte/Jahr) |
| **Relevanz** | 25% | Keyword-Match in Titel/Abstract |
| **Journalqualit√§t** | 20% | Impact Factor / Konferenz-Rang |
| **Open Access** | 15% | PDF √∂ffentlich verf√ºgbar |

**Finaler Score:** 0-100 Punkte

**Beispiel:**
```json
{
  "title": "Lean Governance in DevOps Teams",
  "score": 87,
  "breakdown": {
    "citations": 18,    // 350 Zitationen ‚Üí 18 Pkt
    "recency": 19,      // 2023 ‚Üí 19 Pkt
    "relevance": 23,    // Starker Keyword-Match ‚Üí 23 Pkt
    "quality": 18,      // Top-Konferenz ‚Üí 18 Pkt
    "open_access": 9    // PDF verf√ºgbar ‚Üí 9 Pkt
  }
}
```

---

## üõ†Ô∏è Konfiguration

### Eine Recherche-Konfiguration erstellen

Konfigurationen werden in [config/](config/) als Markdown-Dateien gespeichert. Erstelle eine √ºber:

```bash
# Option 1: Interaktives Setup (empfohlen)
# In Claude Code Chat:
/academicagent
# Agent f√ºhrt dich durch die Konfig-Erstellung

# Option 2: Manuelles Setup
/setup-agent
# Erstellt Konfig ohne Recherche zu starten

# Option 3: Beispiel-Template verwenden
cp config/.example/academic_context_cs_example.md config/my_research.md
# Manuell bearbeiten
```

### Konfig-Struktur

```markdown
# Recherche-Konfiguration

## Forschungsfrage
Wie erm√∂glichen Lean-Prinzipien Governance in DevOps-Teams?

## Keywords
- Prim√§r: Lean Governance, DevOps
- Sekund√§r: Continuous Delivery, Agile Teams
- Verwandt: IT Governance, Process Automation

## Ziel-Disziplinen
- Informatik
- Software Engineering
- Business Management

## Suchparameter
- Jahresbereich: 2015-2024
- Sprachen: Englisch, Deutsch
- Dokumenttypen: Journal-Artikel, Konferenz-Papers

## Qualit√§tsfilter
- Min. Zitationen: 10
- Open Access bevorzugt: Ja
- Zielanzahl: 18 Papers
```

Siehe [config/academic_context.md](config/academic_context.md) f√ºr vollst√§ndiges Template.

---

## üîÑ Fehlerwiederherstellung & Fortsetzung

### Nach Unterbrechung fortsetzen

Falls die Recherche unterbrochen wird (Absturz, Terminal geschlossen, etc.):

```bash
# 1. State validieren
python3 scripts/validate_state.py runs/[Timestamp]/metadata/research_state.json

# Ausgabe zeigt:
# ‚úÖ State g√ºltig
# Zuletzt abgeschlossen: Phase 2
# N√§chste: Phase 3
# Checksum: OK

# 2. Chrome neu starten
bash scripts/start_chrome_debug.sh

# 3. In VS Code fortsetzen
code .
# In Claude Code Chat:
/academicagent

# Agent setzt automatisch bei Phase 3 fort
```

### H√§ufige Probleme

Siehe [ERROR_RECOVERY.md](ERROR_RECOVERY.md) f√ºr detailliertes Troubleshooting:

- **CDP-Verbindungsfehler** - Chrome antwortet nicht
- **CAPTCHA-Erkennung** - Manuelle L√∂sung erforderlich
- **Login erforderlich** - Universit√§ts-Authentifizierung n√∂tig
- **Rate Limits** - Automatischer Retry mit Backoff
- **Netzwerkfehler** - VPN/Verbindungsprobleme
- **State-Korruption** - Wiederherstellungsverfahren

### CDP-Health-Monitor

Der Orchestrator √ºberwacht automatisch die Chrome-Gesundheit alle 5 Minuten:
- Pr√ºft CDP-Verbindung (Port 9222)
- √úberwacht Speichernutzung (warnt bei >2GB)
- Startet Chrome bei Absturz automatisch neu
- Loggt in `runs/[Timestamp]/logs/cdp_health.log`

---

## üõ°Ô∏è Sicherheit

AcademicAgent ist gegen Prompt-Injection-Angriffe geh√§rtet. Wichtige Ma√ünahmen:

- **Instruktions-Hierarchie**: Externe Inhalte werden nur als DATEN behandelt
- **Input-Sanitierung**: HTML-Bereinigung, Injection-Pattern-Erkennung
- **‚≠ê NEW: Safe-Bash-Wrapper**: Framework-enforced Action-Gate f√ºr alle Bash-Aufrufe
- **‚≠ê NEW: PDF Security Validator**: Deep Analysis mit Metadata-Stripping, Redundancy-Detection, Structure-Validation
- **Action Gate**: Validiert Tool-Aufrufe vor Ausf√ºhrung (Source-Tracking: system/user/external_content)
- **Domain-Whitelist**: Nur akademische Datenbanken erlaubt (√ºber DBIS Proxy-Mode)
- **Least Privilege**: Beschr√§nkter Dateisystem- und Netzwerkzugriff
- **Reader/Actor-Trennung**: Read-only-Agents k√∂nnen keine Befehle ausf√ºhren
- **‚≠ê NEW: CDP Fallback Manager**: Auto-Recovery bei Chrome-Ausf√§llen mit Playwright Headless Fallback
- **‚≠ê NEW: Budget Limiter**: Token-Budget-Enforcement (warnt bei 80%, stoppt bei 100%)
- **‚≠ê NEW: Encryption at Rest Docs**: Empfehlungen f√ºr FileVault/LUKS Disk-Encryption

**Sicherheits-Score:** 9.5/10 (95% der Ma√ünahmen implementiert, +5% durch neue Features)

Siehe [SECURITY.md](SECURITY.md) f√ºr vollst√§ndige Sicherheitsdokumentation und Red-Team-Tests.

---

## üìä Typische Recherche-Session

```
User startet Recherche (00:00)
  ‚Üì
/academicagent
  ‚Üì
Interaktive Konfig-Erstellung (00:00 - 00:10)
  ‚Üí Forschungsfrage, Keywords, Filter
  ‚Üì
[Checkpoint 0] Datenbanken validieren (00:15)
  ‚Üí Agent zeigt: 8 kuratierte + 3 DBIS entdeckte = 11 Datenbanken
  ‚Üí User genehmigt
  ‚Üì
[Checkpoint 1] Suchstrings pr√ºfen (00:25)
  ‚Üí Agent zeigt Boolean-Queries f√ºr jede Datenbank
  ‚Üí User genehmigt
  ‚Üì
Phase 2 l√§uft automatisch (00:25 - 02:30)
  ‚Üí Iteration 1: Top 5 Datenbanken ‚Üí 23 Kandidaten
  ‚Üí Iteration 2: N√§chste 5 Datenbanken ‚Üí 52 Kandidaten ‚Üí STOPP
  ‚Üì
[Checkpoint 3] Top 18 aus Top 27 ausw√§hlen (02:30)
  ‚Üí Agent rankt alle Kandidaten nach 5D-Score
  ‚Üí Zeigt Top 27 mit Scores
  ‚Üí User w√§hlt Top 18
  ‚Üì
Phase 4 l√§uft automatisch (02:30 - 03:00)
  ‚Üí L√§dt 18 PDFs nach runs/[Timestamp]/downloads/
  ‚Üì
Phase 5 l√§uft automatisch (03:00 - 03:45)
  ‚Üí Extrahiert Zitate aus allen PDFs mit pdftotext
  ‚Üí 40-50 relevante Zitate mit Seitenzahlen
  ‚Üì
[Checkpoint 5] Zitatqualit√§t pr√ºfen (03:45)
  ‚Üí Agent zeigt Beispielzitate
  ‚Üí User genehmigt
  ‚Üì
Phase 6 l√§uft automatisch (03:45 - 04:00)
  ‚Üí Generiert bibliography.bib (BibTeX)
  ‚Üí Generiert quote_library.json
  ‚Üí Generiert summary.md
  ‚Üì
[Checkpoint 6] Ausgaben best√§tigen (04:00)
  ‚Üí Agent zeigt Ausgabe-Pfade
  ‚Üí User genehmigt
  ‚Üì
‚úÖ Recherche abgeschlossen! (04:00)
```

**Gesamte aktive Zeit:** ~15-20 Minuten (Checkpoints + Konfig)
**Gesamte verstrichene Zeit:** ~4 Stunden (gr√∂√ütenteils automatisiert)

---

## üé® Architektur

### Agent-Struktur

```
Orchestrator (/academicagent)
‚îú‚îÄ‚îÄ Phase 0: DBIS-Navigation
‚îÇ   ‚îú‚îÄ‚îÄ Task: browser-agent
‚îÇ   ‚îî‚îÄ‚îÄ Entdeckt Datenbanken √ºber DBIS
‚îú‚îÄ‚îÄ Phase 1: Suchstring-Generierung
‚îÇ   ‚îú‚îÄ‚îÄ Task: search-agent
‚îÇ   ‚îî‚îÄ‚îÄ Erstellt Boolean-Queries
‚îú‚îÄ‚îÄ Phase 2: Datenbanksuche (Iterativ)
‚îÇ   ‚îú‚îÄ‚îÄ Task: browser-agent (Schleife)
‚îÇ   ‚îî‚îÄ‚îÄ Durchsucht 5 DBs pro Iteration
‚îú‚îÄ‚îÄ Phase 3: 5D-Bewertung & Ranking
‚îÇ   ‚îú‚îÄ‚îÄ Task: scoring-agent
‚îÇ   ‚îî‚îÄ‚îÄ Rankt alle Kandidaten
‚îú‚îÄ‚îÄ Phase 4: PDF-Download
‚îÇ   ‚îú‚îÄ‚îÄ Task: browser-agent
‚îÇ   ‚îî‚îÄ‚îÄ L√§dt ausgew√§hlte Papers herunter
‚îú‚îÄ‚îÄ Phase 5: Zitat-Extraktion
‚îÇ   ‚îú‚îÄ‚îÄ Task: extraction-agent
‚îÇ   ‚îî‚îÄ‚îÄ Extrahiert Zitate mit pdftotext
‚îî‚îÄ‚îÄ Phase 6: Finalisierung
    ‚îú‚îÄ‚îÄ Python-Scripte
    ‚îî‚îÄ‚îÄ Generiert Ausgaben
```

### Tools & Technologien

- **Browser-Steuerung**: Chrome DevTools Protocol (CDP) via Playwright
- **PDF-Verarbeitung**: `pdftotext` (poppler-utils) + `grep`
- **State-Management**: JSON-Dateien mit SHA-256-Checksummen
- **Datenbank-Erkennung**: DBIS-Portal + WebFetch
- **Logging**: Strukturierte Logs pro Phase (JSON)
- **Sicherheit**: Domain-Validierung, Input-Sanitierung, Action-Gating

---

## üß™ Testing & Validierung

### Chrome-CDP-Verbindung testen

```bash
# Chrome starten
bash scripts/start_chrome_debug.sh

# 3 Sekunden warten
sleep 3

# Verbindung testen
curl http://localhost:9222/json/version
# Sollte Chrome-Versionsinformationen zur√ºckgeben
```

### Sicherheitstests ausf√ºhren

```bash
# Vollst√§ndige Red-Team-Testsuite ausf√ºhren
bash tests/red_team/run_tests.sh

# Erwartet: 6/10 automatisierte Tests bestehen (60%)
# 4/10 erfordern manuelle Verifikation
```

### Recherche-State validieren

```bash
# State-Datei-Integrit√§t pr√ºfen
python3 scripts/validate_state.py runs/[Timestamp]/metadata/research_state.json

# Zeigt:
# - Aktuelle Phase
# - Zuletzt abgeschlossene Phase
# - N√§chste ausstehende Phase
# - Checksum-Verifizierung
# - Fortsetzungsf√§higkeit
```

### Unit-Tests ausf√ºhren

```bash
# Test-Dependencies installieren
pip install -r tests/requirements-test.txt

# Unit-Tests ausf√ºhren
python3 -m pytest tests/unit/ -v

# Mit Coverage-Report
python3 -m pytest tests/unit/ -v --cov=scripts --cov-report=term
```

**Test-Coverage:**
- `test_action_gate.py` - Action-Gate-Validierungslogik (18 Tests)
- `test_validate_domain.py` - Domain-Validierung und DBIS-Proxy-Mode (16 Tests)
- `test_sanitize_html.py` - HTML-Sanitierung und Injection-Erkennung (14 Tests)
- `test_retry_strategy.py` - Retry-Handler und Backoff-Strategien (15 Tests)

### CI/CD Pipeline

Das Projekt verwendet GitHub Actions f√ºr automatisierte Tests:

```bash
# Workflow wird automatisch ausgef√ºhrt bei:
# - Push zu main/develop
# - Pull Requests zu main
```

**Pipeline-Jobs:**
1. **setup-test** - Installiert Python, Node.js, System-Dependencies
2. **unit-tests** - F√ºhrt pytest mit Coverage aus
3. **security-tests** - Red-Team-Tests (90% Pass-Rate erforderlich)
4. **script-validation** - Python/Bash-Syntax-Checks
5. **secrets-scan** - Scannt nach API-Keys und Secrets
6. **build-validation** - Pr√ºft Dateistruktur und Agent-Configs
7. **status-report** - Aggregiert Ergebnisse

Siehe [.github/workflows/ci.yml](.github/workflows/ci.yml) f√ºr Details.

### Git-Hooks Setup

Pre-Commit-Hook f√ºr Secret-Scanning installieren:

```bash
# Hook installieren
bash scripts/setup_git_hooks.sh

# Testet automatisch bei jedem Commit:
# - API-Keys (ANTHROPIC_API_KEY, etc.)
# - Passw√∂rter und Tokens
# - Sensitive Dateien (.env, *.pem, SSH-Keys)
# - Gro√üe Dateien (>10 MB Warnung)
```

---

## üîß Erweiterte Nutzung

### Von spezifischer Phase fortsetzen

```bash
# In Claude Code Chat:
/academicagent

# Bei Aufforderung Run-Verzeichnis angeben:
runs/2026-02-18_14-30-00

# Agent l√§dt State und fragt:
# "State zeigt Phase 2 abgeschlossen. Von Phase 3 fortsetzen?"
# ‚Üí ja
```

### Benutzerdefinierte Datenbank hinzuf√ºgen

**Hinweis:** Die Datenbank-Konfiguration erfolgt derzeit √ºber die DBIS-Integration. F√ºr custom databases kontaktiere die Maintainer oder √∂ffne ein GitHub Issue mit deinem Datenbank-Vorschlag.

Zuk√ºnftige Version wird `config/databases.yaml` unterst√ºtzen:

```yaml
# Coming soon in v3.2
- name: Benutzerdefinierte Datenbank
  disciplines:
    - Deine Disziplin
  url: custom-db.com
  access: Subscription
  base_score: 85
```

### Iterative Suchparameter anpassen

Bearbeite Konfig um Suchverhalten zu √§ndern:

```markdown
## Suchparameter
- Databases Per Iteration: 5    # Auf 3 oder 10 √§ndern
- Target Candidates: 50          # Zielanzahl √§ndern
- Max Iterations: 5              # Maximale Iterationen begrenzen
- Min Candidates Per DB: 3       # Unproduktive DBs √ºberspringen
```

### Zitatbibliothek nach Word exportieren

**Option 1: Pandoc (manuell)**

```bash
# Konvertiere BibTeX zu Word
pandoc runs/[Timestamp]/outputs/bibliography.bib \
  -o bibliography.docx \
  --citeproc
```

**Option 2: JSON Export (coming soon)**

Zuk√ºnftige Version wird `scripts/export_quotes.py` enthalten:
```bash
# Coming in v3.2
python3 scripts/export_quotes.py \
  runs/[Timestamp]/outputs/quote_library.json \
  output.docx
```

### Utility-Scripts verwenden

#### Kosten-Tracking

Trackt Claude API-Token-Usage und Kosten:

```bash
# Kosten f√ºr eine Recherche anzeigen
python3 scripts/cost_tracker.py runs/[Timestamp]/metadata/llm_costs.jsonl

# Ausgabe:
# üìä Kosten√ºbersicht
# Gesamt: $2.45
# Nach Agent: browser-agent ($0.89), scoring-agent ($0.67), ...
# Nach Modell: claude-opus-4 ($1.23), claude-sonnet-4 ($1.22)
```

In Agent-Code verwenden:

```python
from scripts.cost_tracker import CostTracker

tracker = CostTracker(run_id="2026-02-18_14-30-00")
tracker.record_llm_call(
    agent_name="scoring-agent",
    model="claude-sonnet-4",
    input_tokens=5000,
    output_tokens=1500,
    phase="phase_3"
)
```

#### Performance-Metrics

Sammelt strukturierte Metriken:

```bash
# Metriken anzeigen
jq '.' runs/[Timestamp]/metadata/metrics.jsonl

# Aggregierte Zusammenfassung
python3 scripts/metrics.py summarize runs/[Timestamp]/metadata/metrics.jsonl
```

In Agent-Code verwenden:

```python
from scripts.metrics import MetricsCollector

metrics = MetricsCollector(run_id="2026-02-18_14-30-00")

# Einfache Metrik
metrics.record("papers_found", 52, unit="count", labels={"database": "IEEE"})

# Zeitmessung
with metrics.measure_time("pdf_download", labels={"file": "paper1.pdf"}):
    download_pdf()
```

#### Retry-Strategien

Exponential Backoff f√ºr fehleranf√§llige Operationen:

```python
from scripts.retry_strategy import retry_with_backoff, RetryHandler

# Als Decorator
@retry_with_backoff(max_retries=3, base_delay=2.0)
def flaky_api_call():
    response = requests.get("https://api.example.com")
    return response.json()

# Als Handler mit Profil
handler = RetryHandler.network_request()  # Vorkonfiguriert f√ºr Network
result = handler.execute(download_file, url="https://...")
```

#### CDP-Wrapper

Sichere Browser-Automatisierung ohne direkte CDP-Aufrufe:

```python
from scripts.cdp_wrapper import create_cdp_client

cdp = create_cdp_client()
result = cdp.navigate("https://ieeexplore.ieee.org")
html = cdp.get_html()
cdp.screenshot("/tmp/page.png")

# Datenbank-Suche
search_result = cdp.search_database(
    database_name="IEEE Xplore",
    search_string="(DevOps) AND (Governance)"
)
print(f"Gefunden: {search_result.papers_found} Papers")
```

#### Sichere Bash-Ausf√ºhrung

Erzwingt Action-Gate-Validierung vor Bash-Befehlen:

```bash
# Via CLI
python3 scripts/safe_bash.py "python3 scripts/validate_state.py runs/latest/state.json"

# Dry-Run (validiert ohne Ausf√ºhrung)
python3 scripts/safe_bash.py --dry-run "curl https://example.com"
# Output: ‚ùå BLOCKIERT: Network request ohne Action-Gate-Freigabe
```

In Agent-Code verwenden:

```python
from scripts.safe_bash import safe_bash_execute

try:
    result = safe_bash_execute(
        command="python3 scripts/process_data.py",
        source="system",
        user_intent="Datenverarbeitung f√ºr Phase 3"
    )
    print(result.stdout)
except SafeBashError as e:
    print(f"Befehl blockiert: {e}")
```

---

## üìñ Dokumentation

### üìö F√ºr Nutzer (Studierende & Forscher)

**[User Guide](docs/user-guide/README.md)** - Vollst√§ndiger Guide f√ºr Endnutzer

- [Erste Schritte](docs/user-guide/01-getting-started.md) - Installation & erste Recherche
- [Grundlegender Workflow](docs/user-guide/02-basic-workflow.md) - 7-Phasen-Workflow verstehen
- [Konfiguration erstellen](docs/user-guide/03-configuration.md) - Optimale Konfigs erstellen
- [Ergebnisse verstehen](docs/user-guide/04-understanding-results.md) - 5D-Bewertungssystem & Outputs
- [Probleme l√∂sen](docs/user-guide/05-troubleshooting.md) - Troubleshooting & Fehlerbehandlung
- [Best Practices](docs/user-guide/06-best-practices.md) - Tipps f√ºr optimale Recherchen

### üõ†Ô∏è F√ºr Entwickler & Contributors

**[Developer Guide](docs/developer-guide/README.md)** - Guide f√ºr Entwickler

- [Architektur-√úbersicht](docs/developer-guide/01-architecture.md) - System-Design & Datenfluss
- [Agent-Entwicklung](docs/developer-guide/02-agent-development.md) - Neue Agents erstellen
- [Datenbanken hinzuf√ºgen](docs/developer-guide/03-adding-databases.md) - Neue DBs integrieren
- [Testing-Guide](docs/developer-guide/04-testing.md) - Unit-, Integration- & E2E-Tests
- [Security-Considerations](docs/developer-guide/05-security.md) - Sichere Entwicklung
- [Contribution-Guide](docs/developer-guide/06-contribution-guide.md) - Zum Projekt beitragen

### üìñ Technische Referenz

**[API Reference](docs/api-reference/README.md)** - Detaillierte API-Dokumentation

- [Agents](docs/api-reference/agents.md) - Agent-Definitionen & Prompts
- [Skills](docs/api-reference/skills.md) - Orchestrator-Skill Dokumentation
- [Utilities](docs/api-reference/utilities.md) - Python-Module Referenz

### üîí Sicherheit & Fehlerbehebung

- **[ERROR_RECOVERY.md](ERROR_RECOVERY.md)** - Umfassender Fehlerbehandlungs-Guide
- **[SECURITY.md](SECURITY.md)** - Sicherheitsh√§rtung & Red-Team-Tests
- **[PRIVACY.md](PRIVACY.md)** - Datenschutzrichtlinie & GDPR-Compliance
- **[docs/THREAT_MODEL.md](docs/THREAT_MODEL.md)** - Bedrohungsmodell & Sicherheitsanalyse

### ‚öôÔ∏è Konfiguration & Technisches

- **[docs/DBIS_USAGE.md](docs/DBIS_USAGE.md)** - Technische DBIS-Integration (f√ºr Agents)
- **[UPGRADE.md](UPGRADE.md)** - Upgrade-Anleitung zwischen Versionen
- **[CODE_OF_CONDUCT.md](CODE_OF_CONDUCT.md)** - Community-Verhaltenskodex

---

## ü§ù Beitragen

Beitr√§ge sind willkommen!

### ‚úÖ K√ºrzlich Implementiert (v3.0)

Die folgenden Infrastruktur-Verbesserungen wurden bereits umgesetzt:
- ‚úÖ CI/CD-Pipeline mit GitHub Actions (7 automatisierte Jobs)
- ‚úÖ Unit-Tests mit pytest (50+ Tests, Coverage-Tracking)
- ‚úÖ Kosten-Tracking f√ºr Claude API-Nutzung
- ‚úÖ Performance-Metriken-System (strukturiertes Logging)
- ‚úÖ Retry-Mechanismen mit Exponential Backoff
- ‚úÖ Threat-Model und Sicherheitsanalyse
- ‚úÖ CDP-Wrapper f√ºr sichere Browser-Automatisierung
- ‚úÖ Git-Hooks f√ºr Secret-Scanning

### üéØ Offene Verbesserungsbereiche

1. **Datenbank-Abdeckung**
   - Disziplin-spezifische Datenbanken hinzuf√ºgen (z.B. PsycINFO, ERIC, MedLine)
   - DBIS-Relevanz-Scoring mit ML verbessern
   - Alternative Zugangsmethoden f√ºr Paywall-Datenbanken

2. **Bewertungsalgorithmus**
   - H-Index f√ºr Journalqualit√§t integrieren
   - Domain-spezifisches Relevanz-Scoring (trainiert auf Fachbegriffen)
   - Automatische Duplikatserkennung zwischen Datenbanken

3. **Internationalisierung**
   - Mehrsprachige Suchstrings (automatische √úbersetzung)
   - Unterst√ºtzung nicht-englischer Datenbanken (z.B. CNKI f√ºr Chinesisch)
   - Lokalisierte Konfigurations-Templates

4. **Ausgabeformate**
   - Zitierstile (APA, MLA, Chicago, IEEE)
   - Export zu Zotero, Mendeley, EndNote (RIS/BibTeX-Import)
   - Annotierte Bibliographie-Generierung

5. **Benutzeroberfl√§che**
   - Webbasierte Konfigurations-UI (React/Next.js)
   - Echtzeit-Fortschritts-Dashboard mit Streaming-Updates
   - Visuelle Zitat-Bibliothek mit Highlighting

---

## üêõ Bekannte Einschr√§nkungen

1. **DBIS-Abh√§ngigkeit**: Ben√∂tigt universit√§ren DBIS-Zugang
2. **Manueller Login**: Einige Datenbanken ben√∂tigen menschliche Authentifizierung
3. **CAPTCHA-Handling**: Erfordert manuelle L√∂sung
4. **Rate Limits**: Aggressive Suche kann Rate Limits ausl√∂sen
5. **PDF-Extraktion**: Qualit√§t h√§ngt von PDF-Textebene ab

---

## üìÑ Lizenz

MIT License - Siehe LICENSE-Datei f√ºr Details

---

## üôè Danksagungen

- **Anthropic** - Claude Code und Agent SDK
- **DBIS** - Database Information System (Universit√§t Regensburg)
- **Poppler** - PDF-Textextraktions-Bibliothek
- **Playwright** - Chrome DevTools Protocol Client

---

## ü§ñ ChatGPT-Konfigurationsgenerator

Du kannst ChatGPT verwenden, um deine Recherche-Konfiguration automatisch zu erstellen. Kopiere den folgenden Prompt und f√ºge ihn in ChatGPT ein:

```text
Du bist ein akademischer Konfigurationsassistent f√ºr AcademicAgent, ein autonomes Literatur-Recherche-System.

DEINE AUFGABE:
Erstelle basierend auf den Angaben des Nutzers eine vollst√§ndige Recherche-Konfiguration im Markdown-Format.

KONFIGURATIONS-STRUKTUR:
Eine AcademicAgent-Konfiguration muss folgende Abschnitte enthalten:

# Recherche-Konfiguration

## Forschungsfrage
[Eine pr√§zise, forschungsleitende Frage]

## Keywords
- Prim√§r: [Haupt-Schlagw√∂rter, die das Kernthema definieren]
- Sekund√§r: [Erg√§nzende Begriffe, die den Kontext erweitern]
- Verwandt: [Synonyme, verwandte Konzepte, alternative Begriffe]

## Ziel-Disziplinen
[Wissenschaftliche Disziplinen, z.B. Informatik, BWL, Jura, Psychologie]

## Suchparameter
- Jahresbereich: [z.B. 2015-2024]
- Sprachen: [z.B. Englisch, Deutsch]
- Dokumenttypen: [z.B. Journal-Artikel, Konferenz-Papers, Dissertationen]

## Qualit√§tsfilter
- Min. Zitationen: [z.B. 10]
- Open Access bevorzugt: [Ja/Nein]
- Zielanzahl: [Standard: 18 Papers]

ITERATIVE SUCHPARAMETER (Optional):
## Erweiterte Suchparameter
- Databases Per Iteration: [Standard: 5]
- Target Candidates: [Standard: 50]
- Max Iterations: [Standard: 5]
- Min Candidates Per DB: [Standard: 3]

ANWEISUNGEN:
1. Frage den Nutzer nach:
   - Thema, Forschungsfrage oder Gliederung
   - Akademischer Kontext (Studiengang, Seminar, etc.)
   - Zeitrahmen und Umfang
   - Sprachpr√§ferenzen

2. Generiere basierend darauf:
   - Eine pr√§zise Forschungsfrage
   - 3 Kategorien von Keywords (Prim√§r, Sekund√§r, Verwandt) mit je 3-5 Begriffen
   - Passende Ziel-Disziplinen
   - Sinnvolle Suchparameter und Qualit√§tsfilter

3. Gib die Konfiguration als kopierbaren Markdown-Block aus

4. Erkl√§re kurz, wie die Konfiguration verwendet wird:
   "Speichere diese Konfiguration als `config/deine_recherche.md` im AcademicAgent-Verzeichnis und starte dann `/academicagent` in Claude Code."

BEISPIEL-INTERAKTION:
Nutzer: "Ich schreibe eine Bachelorarbeit √ºber KI-Ethik in autonomen Fahrzeugen"
Assistent: [Generiert vollst√§ndige Konfiguration mit passenden Keywords wie "AI Ethics", "Autonomous Vehicles", "Moral Decision Making", etc.]

JETZT: Frage den Nutzer nach seinem Thema/seiner Forschungsfrage!
```

**Verwendung:**

1. Kopiere den obigen Prompt in ChatGPT
2. Beschreibe dein Forschungsthema, deine Gliederung oder Forschungsfrage
3. ChatGPT generiert eine fertige Konfigurationsdatei
4. Speichere die Ausgabe als `config/deine_recherche.md`
5. Starte `/academicagent` in Claude Code

---

## üìû Support

- **Issues**: [GitHub Issues](https://github.com/jamski105/AcademicAgent/issues)
- **Diskussionen**: [GitHub Discussions](https://github.com/jamski105/AcademicAgent/discussions)
- **Dokumentation**: Siehe Docs in diesem Repository

---

## üîÑ Versionshistorie

- **v3.1** (2026-02-19) - Security-Hardening, macOS-Only, Script-Robustheit
  - ‚úÖ Safe-Bash Wrapper, PDF Security Validator, CDP Fallback Manager
  - ‚úÖ Budget Limiter, Encryption at Rest Docs
  - ‚úÖ Alle Scripts mit `set -euo pipefail`
  - ‚úÖ TTY-Checks, Cleanup-Traps, bc-Fallbacks
  - ‚ö†Ô∏è Linux-Support entfernt (macOS-only)
- **v3.0** (2026-02-18) - Datenbank-Strategie V3.0 mit dynamischer DBIS-Erkennung
- **v2.5** (Vorherig) - Iterative Datenbanksuche
- **v2.0** (Vorherig) - 5D-Bewertungssystem
- **v1.0** (Vorherig) - Erstes Release

Siehe [UPGRADE.md](UPGRADE.md) f√ºr Migrations-Anleitung.

---

**Viel Erfolg bei der Recherche! üìöü§ñ**
